[ { "title": "CISSP thoughts & notes", "url": "/posts/cissp-notes/", "categories": "Study", "tags": "CISSP", "date": "2024-10-10 04:00:00 +0000", "snippet": "IntroThe Certified Information Systems Security Professional (CISSP) certification is a well-known credential for info security professionals. For me, getting this certification was a long-term goa...", "content": "IntroThe Certified Information Systems Security Professional (CISSP) certification is a well-known credential for info security professionals. For me, getting this certification was a long-term goal. I wanted to formalize my skills and gain some recognition in the cybersecurity world.I originally planned to study for the CISSP before starting my PhD, hoping to finish it while I was studying. But balancing both was tough. After I graduated, I finally found the right time to focus on the certification.I studied for about three months, putting in 2-3 hours during the week and 4-5 hours on weekends. On September 9, 2024, I passed the CISSP exam after just 100 questions!Is it worth it?Before committing to any certification, I always ask if it’s really worth the time and money. Will it truly help my career, or is it just another title to add to the wall? To make a good choice, I talked to friends and colleagues and read through a lot of articles and forums. Opinions were mixed, but most agreed it can boost career prospects, even if it doesn’t necessarily make you a better cybersecurity professional. I agree with that, but I also keep in mind that the CISSP exam isn’t meant to test hands-on skills. It assumes candidates are already experienced cybersecurity professionals, and (ISC)² verifies this after passing the exam. With that in mind, here are my reasons for pursuing the CISSP certification.Non-technical aspects of cyber securityThe CISSP exam is particularly interesting because it bridges the gap between the technical and non-technical aspects of cybersecurity. Coming from a background as a software developer and researcher, where I’ve delved deeply into the technical workings of security mechanisms, I realized I had been missing key layers that are essential to securing organizations but are not purely technical.Topics such as data ownership, policies, procedures, risk management, business continuity, and legal considerations were relatively new to me. Although I had an intuitive understanding of their importance while working in cybersecurity environments, they were always handled by others. Studying for the CISSP helped me see how these elements fit into the broader security picture, giving me a more comprehensive understanding of how they all interconnect.Systematization of knowledgeWhen studying for the CISSP exam, you’ll notice it covers a wide range of topics. The official study guide alone is over 1,000 pages, so there’s a lot to take in. But the exam isn’t about memorizing every protocol or system—it’s more about understanding key concepts, how they’re applied in the real world, and how different aspects of security work together.What I found really interesting during my preparation was learning the backstory behind some technologies—why certain choices were made and how things evolved over time. While that kind of historical insight might not be something you use day-to-day, it’s definitely valuable knowledge.CISSP gives you a big-picture view of cybersecurity, and that was the most useful part for me. As someone with a Linux background, I also appreciated getting to learn about other proprietary security solutions. Overall, the study material offers a really solid overview of cybersecurity, which makes the whole certification process worth it.LanguageIn the industry, every team has its own way of communicating. Managers focus on deliverables and risks, engineers talk about features and deadlines, while security teams discuss vulnerabilities and threats. Studying for the CISSP helps you understand how each group views and talks about security.Since communication is crucial in cybersecurity, the CISSP equips you with the language needed to effectively engage with stakeholders, managers, engineers, and security professionals alike. The next step is putting this knowledge into practice in real-world situations.Formal RequirementThe CISSP exam mainly shows you’ve got a solid grasp of non-technical security knowledge, but adding it to your CV can still give you a boost during hiring. Some job listings mention CISSP as a “nice-to-have,” which can help youget through that first HR screen.Still, I think certifications like CISSP are best as a bonus rather than the main focus. Having a strong GitHub, a blog, or a good portfolio of projects often goes further in showing what you can actually do.Study materialsThere are a ton of books and question banks out there for CISSP prep, but just make sure you’re using more recent ones. I like digital materials, but I also enjoy writing notes by hand. I mainly used the Sybex Study Guide and the All-in-One Exam Guide, focusing on the parts I needed. Then I did practice questions to find my weak spots and went back to review those areas. Here are the resources that helped me the most.Oreilly libraryIf you can learn from digital materials instead of paper books, Oreilly library is definitely worth considering. It costs about $50 a month (as of October 2024) and gives you access to a ton of books and videos, including the Sybex Official Study Guide and some exam practice books. I think this option is more cost-effective and environmentally friendly than buying physical books.Link: https://www.oreilly.com/search/?q=cissp&amp;rows=100Learnzapp Learnzapp is a great resource for practicing questions once you’ve read the books and tackled the questions in them. It offers both a mobile app and a web version, and you can even practice in exam mode. I found it really helpful to see just how tiring it can be to answer over 100 questions in one sitting.Link: https://isc2-learnzapp.web.app/homeStudy Notes and Theory Another solid resource is the study materials and questions from Luke Ahmed. His question set is intentionally quite challenging, so I recommend using it after you’ve gone through all the other materials. Just avoid doing these questions right before the exam. Since they can be harder and trickier than the actual test, you might end up feeling discouraged or lose confidence if you can’t hit the passing score.Link: https://www.studynotesandtheory.com/Destination Certification Videos Rob Witcher’s CISSP MindMaps are great for reviewing and pinpointing the areas where you need more study. The videos cover all the domains and summarize the key topics effectively.Link:https://www.youtube.com/watch?v=hf5NwUSEkwA&amp;list=PLZKdGEfEyJhLd-pJhAD7dNbJyUgpqI4puTechnical Institute of America I found Andrew Ramdayal’s videos just before the exam, and they really helped me feel confident about the topics. After tackling his 50 CISSP Practice Questions, I knew I was ready to take the exam.Link: https://www.youtube.com/watch?v=qbVY0Cg8NtwSummaryPassing the CISSP exam was a fantastic journey. I learned a ton, and I’m really glad I went for it. Even before the exam, I wasn’t sure if I was ready, but I know I tend to second-guess myself. I totally recommend it for anyone who’s been in cybersecurity for a few years and wants a good overview of the field. The certification is just the cherry on top.Next on my list - maybe OSCP!" }, { "title": "OPA for User Registration", "url": "/posts/opa-registration/", "categories": "Authorization, IAM", "tags": "OPA, Intermediate", "date": "2024-06-30 04:00:00 +0000", "snippet": "BackgroundIdentity management is often far more complex in practice than it seems in theory. Simple user journeys quickly become convoluted when edge cases and exceptions are taken into account. Th...", "content": "BackgroundIdentity management is often far more complex in practice than it seems in theory. Simple user journeys quickly become convoluted when edge cases and exceptions are taken into account. This complexity is further amplified when identity management is being introduced for the first time in an organization, where a lack of standardization, identity silos, and poor data quality often present significant obstacles.In many cases, organizations have multiple identity stores tied to different applications, making it difficult to establish a unified view of the user. The process of generating a “golden record” — a single, unique, and well-defined user record compiled from various fragmented sources — becomes a daunting technical challenge. This complexity is exacerbated when business rules are not clearly defined upfront and need to be discovered and implemented during the process. Additionally, data quality is frequently compromised due to legacy systems and the natural erosion of information over time.Given these challenges, it is crucial to implement a robust and flexible identity management system capable of accommodating complex business rules. The system should use an approach that is both technically sound and easy to understand, minimizing issues during the translation of business logic into code. Furthermore, changes to these business rules should not necessitate a full software development lifecycle, but rather be managed as configuration changes, enabling faster and more adaptable updates.In this article, I explore a solution implementing centralized policy decision point based on open-source components for just-in-time user registration. Please note that this is not intended as an evidence-based evaluation but rather a description of what worked for me in solving this problem, and it may help you as well. The approach outlined below uses Open Policy Agent (OPA) as a policy engine and has been successfully deployed in production for some time.GoalsFirst, let’s enumerate the goals for the system:FundamentalB1. The solution needs to be production ready and verified in a real-world scenario.B2. We don’t have unlimited budget, so the solution should be cost-effective, easy to maintain and modify.FunctionalF1. Encapsulate business logic in a separate component with easy interface.F2. Enable complex logic on user attributes and relations between them.F3. Fast JIT decision what actions identity management system should take (e.g., deny the process).F4. Generate data modification instructions for the identity management system.F5. Standardised way of defining rules, which can be extended with other use cases if needed.UsabilityU1. Business (a.k.a non-technical employees) can understand the logic of the policy and even define their own rules.U2. Developers can understand the process and does not have to translate business requirements into code.U3. It is easy introduce changes to the rules and intergrate with existing IDM stack.U4. Versioning following GitOps principles.DesignThe high-level design of the solution is as follows: IDM aggregates data from various sources. IDM creates a data bundle that represents the user. Bundle is sent to the evaluation engine. Evaluation engine uses the rules to make a decision. Evaluation engine returns the decision and actions to IDM.The diagram below shows the high-level design of the solution: flowchart LR A[Data Source A] &amp; B[Data Source B] &amp; C[Data Source C] -- User Data --&gt; IDM IDM -- Aggregated Data --&gt; EV[Evaluation engine] EV[Evaluation engine] -- Result --&gt; IDMProposed SolutionHaving previous experience with OPA (Open Policy Agent) for access management,my idea is to try to use it for the user registration process.OPA allows to evaluate policies which encode business logic using rego language.OPA executes declarative policies completely decoupled from the application code. Any party in your system cansimply trigger a REST call to OPA engine with input data for evaluation.For example, below is a sample of a simple policy that checks access policy for API calls to the HTTP server (source OPA documentation):package httpapi.authzimport rego.v1# bob is alice's manager, and betty is charlie's.subordinates := {\"alice\": [], \"charlie\": [], \"bob\": [\"alice\"], \"betty\": [\"charlie\"]}default allow := false# Allow users to get their own salaries.allow if {\tinput.method == \"GET\"\tinput.path == [\"finance\", \"salary\", input.user]}# Allow managers to get their subordinates' salaries.allow if {\tsome username\tinput.method == \"GET\"\tinput.path = [\"finance\", \"salary\", username]\tsubordinates[input.user][_] == username}In this example based on the request metadata, OPA engine makes decision to allow or deny access to the resource.For example, the data as shown below sent for the evaluation will result with result true.{ \"method\": \"GET\", \"path\": [\"finance\", \"salary\", \"alice\"], \"user\": \"alice\"}This can be easily extended to the user registration process to decide if user should be registered or not. What about the actions that should be taken by the IDM system? OPA can help with that as well.Instead of returning just true or false, the engine can return a complex JSON object that is constructed accordinglyto the rules which I show in the implementation section.AlternativesBefore selecting OPA, I evaluated the approaches of building the rules engine from scratch as a native extension of the identity management system as well as using BPMN engine such as Camunda Zeebe.While native implementation is tempting with its flexibility, performance and tight integration with the IDM system, it fails to deliver on the usability side.Source code typically mixes business logic with language specific constructs, making it hard to understand for non-technical (and sometimes technical) employees.On top of that, designing and implementation of the rules engine is a significant development effort increasing the cost of the solution.My first thought of viable solution that binds business logic and technical implementation was to use BPMN engine.BRPN (Business Process Model and Notation) defines an XML-based representation of the business flow and binds it with software executions.Importantly, the flow design can be defined in the graphical editor without knowingthe underlying technology. While this approach might have worked, I found it too high-level for the task at hand.In my use case the logic needs to evaluate every single field of the user and make the decision.It would mean that steps of the BPMN had to be very granular which decreses performance (each one calls method in the BPMN worker) or the logic would have to be implemented in the worker which is very close to the native implementation.OPA for the rescueLet’s start with the evaluation of the requirements.OPA is definitely production-ready and tested by many companies (B1).The open-source version is sufficient for this use case, and the running cost is relatively small.The policy is defined as a text file and can be modified in any editor (B2). This completes our fundamental requirements.Regarding functional requirements, Rego files contain the entire business logic.The Rego file is evaluated in the OPA engine, a separate component (e.g., a Docker container) with a clear REST API.To get a policy decision, literally one REST API call is needed, so we have F1 covered.In the case of F2, the Rego language is powerful; however, I must admit that, with a typical software development mindset (i.e., writing step-by-step instructions to achieve results), defining the rules might not feel intuitive. For example, there are no for loops in Rego, and if statements are declared differently than what you might be familiar with in popular languages like Java or JavaScript (see more in rego design principles).However, thanks to this design, complex policies with broad and deep execution paths can be described concisely.Conditions between static data, input data, and dynamically calculated data can be easily defined.One drawback from my experience with Rego is that it is not a full-fledged programming language, and some operations available by default or through native libraries are missing. For example, simple geofencing calculations require basic mathematical operations like sine and cosine, which are not available in Rego. However, you can extend the Rego engine by writing Go code and extending the OPA engine. Alternatively, in my case, I queried an external service for the result using OPA’s HTTP client.Therefore, I believe that the requirement F2 is sufficiently met.F3 is a strong point of OPA. The engine is very fast and can evaluate policies in a fraction of a second.For our complex policy (with over 2,000 lines of code), the evaluation time is between 2-4ms.Though this is not a benchmark result suitable for OPA performance comparisons, the outcome is far better than required for our use case, so F3 is met.OPA policies are not limited to returning a single boolean value. They can return a complex JSON object.With that, you can use policy rules to construct a JSON object that orchestrates actions to be taken by the IDM system.Actions like modifying a user’s email in Active Directory or updating contact information in the CRM system can be easily defined.In my case, OPA rules were used to construct LDAP LDIF files that were later executed by the IDM system.Therefore, F4 is met.Making complex rules simple is a challenge, and regardless of the technology, one can end up with spaghetti code.However, Rego has the advantage of flattening the logic and promoting the creation of short blocks that represent policy conditions.This contributes to the readability and standardization of rule definitions. Regarding extensibility, once created, a policy can be easily extended—up to the point that it breaks the agreed interface with the client (e.g., a new field in the response).But even then, the change is easy to introduce and does not require much effort.Therefore, F5 is met.Now let’s look at usability.To my surprise, OPA was easy to understand for the business. Once rules are named in understandable language (e.g., is_user_in_hr_group), the rule and entire policy become more like a recipe than code.I found that after initial training, non-technical employees were able to understand the policy and even define their own rules.Therefore, in my opinion, U1 is met.Easily understandable but technical representations of policy rules also benefit the development side.Business requirements, typically delivered as a set of plain English-described conditions, are much easier to translate into Rego code than into native code.The reverse is also true: once requirements are expressed in Rego, it is easier to perform reverse reasoning and understand the business logic.Therefore, U2 is met.Regarding U3, I have already discussed policy updates and integration via a single REST call.In terms of versioning (U4), rego files are text files that can be easily versioned using Git.Implementation examplesBelow, I share a few samples of how the policy can be implemented. PLease note that that those exmaples are notcomplete and are simplified for the purpose of this article.Ex1. The policy is designed to have a single entrypoint. Below, you can see a rule called decision, which has similarfunction as main method in programming languages. It is being executed directly from the REST API, and defines the structure of the response. It aggregates results from other rules into single JSON body.decision := response { response := { \"ruleImplemented\":rule_implemented, \"input\": policy_input, \"ldap\": ldap, \"error\": error, \"warn\": warn, \"metadata\": metadata, \"version\": policy_version, \"timestamp\": time.format(time.now_ns()) }}Ex2. The policy also runs the check of the data quality. If something is wrong thewarning message is added to the response. Similar approach is done for errors.warn[warn] { user_is_in_ldap count(ldap_attribute_x) == 0 warn := \"MISSING_LDAP_ATTRIBUTE_X: LDAP data is missing the x attribute\"}Ex3. As I mentioned before, policy also creates steps for other systems to execute. The example below shows how ldif modifyinstruction is created for LDAP system.ldap := ldap_recs {\tldap_recs := {\t\t\"roles\":[{\t\t\t\"dn\": \"cn=member,ou=roles,dc=example,dc=com\",\t\t\t\"changetype\": \"modify\",\t\t\t\"add\": \"member\",\t\t\t\"member\": concat(\",\",[concat(\"=\",[\"uid\",input.username]),\"ou=users,ou=external,dc=example,dc=com\"])\t\t}]\t}}SummaryIn this article, I demonstrated how Open Policy Agent (OPA) can be used to implement centralized policy evaluation for just-in-time user registration. The solution is production-ready, cost-effective, and easy to maintain and modify. Additionally, it has the potential to be extended to other use cases, which I am currently exploring.The key takeaways are that, despite an initial learning curve, OPA and its Rego language offer powerful capabilities for implementing complex business logic. Another important point is that OPA can return more than just policy decisions, offering flexibility in its responses. Finally, I believe that the simplicity of Rego’s syntax, combined with well-structured naming conventions, can significantly reduce the gap between business requirements and technical implementation, minimizing friction and misunderstandings." } ]
