[ { "title": "Cybersecurity - the longest journey", "url": "/posts/GIAC-notes/", "categories": "Lessons learned", "tags": "GIAC, SANS, WiCyS", "date": "2024-12-19 04:00:00 +0000", "snippet": "Part One: The CallingEver since I joined the ranks of IT professionals, I’ve been constantly surprised by how patchy cybersecurity awareness is in some organizations. This unfortunately translates ...", "content": "Part One: The CallingEver since I joined the ranks of IT professionals, I’ve been constantly surprised by how patchy cybersecurity awareness is in some organizations. This unfortunately translates into uneven and often inadequate security controls. As much as one might be reluctant to admit it, securing organizational assets is an uphill battle—especially when there’s never enough budget to implement the right solutions in the right way. To make matters worse, when cybersecurity is treated as a liability, it often proves to be exactly that. A self-fulfilling crisis, if you will.Let’s run a quick test, shall we?How many of you have seen login credentials for both test and production accounts stored in plaintext on an internally available website? How about the all-time classic—API secrets accidentally pushed to a repository (extra points if the repo was publicly available)? Yes, you can rotate the secrets and clear out the Git history so no trace of the mishap remains, but what lesson have you learned? And what can be done to ensure it doesn’t happen again to anyone else, including your future self?I was introduced to good cybersecurity practices during my first gig as a budding quality analyst back in Poland (here’s to you, dear Sagiton folk). My team taught me the value of static code analysis and automated security checks even before I could fully grasp their significance in strengthening the security posture of a system. Many years later, I found myself regularly revisiting those areas that had always sparked my interest, but which I’d never really had the chance to fully explore. It was clearly something I was drawn toward, no matter my role in the past. Soon, I realized it was only a matter of time before I made the pivot. The only thing I didn’t know was when and how the pivot would happen. I admit I dragged my feet for months, waiting for a sign—even if I didn’t necessarily believe in the supernatural.This is why, when I first heard of the WiCyS scholarship, I thought: Well, this is it. You’re not getting a better chance. Go for it. See what happens. So, that’s exactly what I did—starting with the initial Capture the Flag event back in November 2023, then somehow making it into Tiers Two and Three, and finally becoming one of the sixty-odd women who advanced to the final Tier.Was it one of the most intense and challenging years of my life? Heck yes!Knowing what I know now, would I do it all over again?In a heartbeat.Part Two: The CompanyYou see, there are at least two choices when you find your calling and decide to act on it: you either try to go it alone, or you gather your party before venturing forth. I’m not a big fan of survival mode, so I wholeheartedly welcomed the opportunity to gain new skills and knowledge alongside some of the most talented and determined women I’ve ever had the chance to meet. Months of Tier 1-3 challenges had already brought us closer together, and even if we couldn’t compare all our notes (intellectual property struggles are real!), the sense of a unified community was definitely there. Weekly online catch-ups only strengthened the bond, with WiCyS alumni supervising our progress and offering help whenever it was needed.And the best part? All program members were granted a scholarship to attend the annual WiCyS conference, which this year took place in Nashville, Tennessee. I wish I could offer a longer description of how electrifying the conference was or how everything about it felt like finally coming home after years of aimless wandering—but I can’t and won’t. The three days flew by so quickly that I could hardly catch my breath, let alone find everyone I’d made a solid plan to grab coffee with.This is why I promised myself to go back as soon as possible—and plan it better this time, allowing enough time for both learning and making new friends. After all, both are equally important.Part Three: The QuestThe main part of the scholarship included access to three cybersecurity courses developed by the SANS Institute, a world-renown resource for high-quality cybersecurity education. Each course concluded with two GIAC practice exams, and passing at least one of them with a satisfactory score (80% in our case) unlocked an attempt at the real exam. The linear structure of this main quest worked wonders for a busy brain like mine, making it relatively easy to focus on the three-part journey ahead.Here are some lessons learned from each stage:GIAC Foundational Cybersecurity Technologies (GFACT) The course was a great introduction to IT, computing and security essentials, presented in an engaging way by James Lyne, the CTO of SANS. What stood out the most was James’ passion for every topic he covered, from hardware components to cyber forensics, along with his witty analogies that made seemingly unrelated concepts both entertaining and easier to grasp (e.g., why computer networks are like Rolo chocolates). I had a few years of IT experience under my belt, so achieving a 96% score on my final exam was relatively easy. Was it completely effortless? Absolutely not! Since I’d never earned a computer science or IT degree, there were certain gaps in my understanding that the course helped me fill. Some gaps remained—hence the missing 4%—but that was an error margin I could definitely live with. The main challenge of this stage was learning how to navigate the scholarship program and stay consistent with weekly Zoom check-ins. Due to time zone differences, these sessions fluctuated between 6–7 a.m., which gave me a newfound appreciation for earlier bedtimes. Once I found my rhythm, though, nothing could distract me from my goal of sitting the exam and passing it within the first two months of starting the course.GIAC Security Essentials (GSEC) If GFACT was a stepping stone, I would compare GSEC to a rabbit hole of the most intriguing kind—the depth and breadth of the course material were not for the faint-hearted. If that wasn’t enough, the course included multiple resources to explore in your own time. With the staggering number of areas covered, the author, Bryan Simon, did a fantastic job maintaining an even pace and high level of engagement throughout. I especially appreciated his anecdotes, which were a welcome break when the material became a bit too technical to stay focused for extended periods. What I enjoyed most at this stage was the hands-on aspect of the course. As someone with an extremely practice-oriented brain, I need to get my hands dirty with something new before I can confidently say I understand its inner workings. The lab setup and tasks provided a fresh, practical level of insight that I’d been looking for, helping to sharpen my PowerShell and Bash skills well beyond the everyday basics. I passed my final exam with a score of 89% in three months, which I was quite satisfied with. I’m fairly certain I performed better on the lab section than the practical one, due to a small mishap—three-quarters into the exam, I accidentally clicked the button to answer all the skipped questions, forcing me to speed-run through them and the remainder before I could even get to the hands-on portion. Despite the incident, my strategy to divide the four-hour exam into two halves almost worked, even if I felt like an internally screaming possum during the second half.GIAC Certified Incident Handler Certification (GCIH) The last exam was the biggest challenge—not because of the material (although its depth was truly impressive, and I thought nothing could surprise me after GSEC!) but because of my time blindness. Despite a planned trip to the U.S. to attend the annual WiCyS conference, followed by a 1.5-month family visit to Poland, and simultaneously juggling an Advanced Diploma of IT course, I decided to start my GCIH prep before the flight to the U.S. Mistake number one! Unsurprisingly, I couldn’t maintain my focus on the course material during the first month. Even though I had all my printed course books with me, traveling with an extra five kilos of paper wasn’t always the most practical choice (mistake number two). Mistake number three was assuming—based on my luck with lab questions on the GSEC exam—that practicing the course labs only once and simply rereading them for revision would suffice. It didn’t, and my final score of 87% reflected my poor judgment. Yet another lesson learned. :) That said, I thoroughly enjoyed the prep and exam experience itself. Hats off to the course author, Joshua Wright, who managed to make it as engaging and entertaining as a conversation with a good friend, never losing momentum. Even if I never work as an incident handler, the transferable skills and knowledge I gained are already proving useful in my current areas of focus.Part Four: The FutureHaving completed both the security training scholarship and my Advanced Diploma of IT (Cybersecurity), I can confidently say I see myself thriving in this field over the next few years. I’ve already been fortunate enough to secure a position as an Identity Engineer, joining not one but two fantastic teams filled with kind and talented professionals.As I continue this exciting journey, I’ll share more lessons learned and create guides in the hope that, one day, they might help solve your problems and make your lives easier.Identity and access management is a cornerstone of every system you can imagine, so you’d better pack a good pair of walking boots.Next stop: everywhere!" }, { "title": "CISSP thoughts & notes", "url": "/posts/cissp-notes/", "categories": "Study", "tags": "CISSP", "date": "2024-10-10 04:00:00 +0000", "snippet": "IntroThe Certified Information Systems Security Professional (CISSP) certification is a well-known credential for info security professionals. For me, getting this certification was a long-term goa...", "content": "IntroThe Certified Information Systems Security Professional (CISSP) certification is a well-known credential for info security professionals. For me, getting this certification was a long-term goal. I wanted to formalize my skills and gain some recognition in the cybersecurity world – what better way to prove myself was there?I originally planned to study for CISSP before starting my PhD, hoping to finish it while I was studying. But balancing both was tough, even impossible at times. After I graduated, I finally had time to regain my focus and double down on the certification prep.I scheduled regular study sessions for about three months, putting in 2-3 hours during the week and 4-5 hours on weekends. On September 9, 2024, I passed the CISSP exam after answering just 100 questions!Is it worth it?Before committing to any certification, I always ask if it’s really worth the time and money. Will it truly help my career, or is it just another title to add to the wall? To make a good choice, I talked to friends and colleagues and researched a lot of industry articles and forums. Opinions were mixed, but most agreed the certification can boost career prospects, even if it doesn’t necessarily make you a better cybersecurity professional. I agree with that, but I also keep in mind that the CISSP exam isn’t meant to test hands-on skills. It assumes candidates are already experienced cybersecurity professionals, and (ISC)² verifies this after passing the exam. Having said all that, here are my top 4 reasons for pursuing the CISSP certification.Non-technical aspects of cybersecurityThe CISSP exam is particularly interesting because it bridges the gap between the technical and non-technical aspects of cybersecurity. With a complex background as a software developer and researcher, and having delved deeply into the technical workings of security mechanisms, I realized I had been missing key defense layers that are essential to securing organizations, but are not purely technical.Topics such as data ownership, policies, procedures, risk management, business continuity and legal considerations were relatively new to me. Although I had an intuitive understanding of their importance while working in cybersecurity environments, they were always handled by other stakeholders. Studying for CISSP helped me see how these elements fit into the broader security picture, giving me a more comprehensive understanding of how they all interconnect.Systematization of knowledgeWhen studying for the CISSP exam, you’ll notice that it covers a wide range of topics. The official study guide alone is over 1,000 pages, so there’s a lot to take in. But the exam isn’t about memorizing every protocol or system—it’s more about understanding key concepts, how they’re applied in the real world, and how different aspects of security work together to achieve the best security posture.What I found intriguing during my preparation was learning the backstory behind some technologies—why certain choices were made and how things evolved over time. While that kind of historical insight might not be something you use day-to-day, it’s definitely valuable knowledge.CISSP gives you a big-picture view of cybersecurity, and that was definitely the most useful part for me. As someone with a Linux background, I also appreciated getting to learn about other proprietary security solutions. Overall, the study material offers a really solid overview of cybersecurity, which makes the whole certification process worth it.LanguageIn the industry, every team has its own way of communicating. Managers focus on deliverables and risks, engineers talk about features and deadlines, while security teams discuss vulnerabilities and threats. Studying for the CISSP exam helps you gain a deep understanding of how each group perceives and talks about security.Since communication is a crucial aspect of cybersecurity, CISSP equips you with the language needed to effectively engage with stakeholders, managers, engineers and security professionals alike. The next step is putting this knowledge into practice in real-world situations.Formal RequirementThe CISSP exam primarily validates that you’ve got a solid grasp of non-technical security knowledge, but adding it to your CV can still give you a boost during your next technical job search. Some job listings mention CISSP as a “nice-to-have,” which can help youget through that first HR screen.Final thought: I think certifications like CISSP are best treated as a bonus rather than the main objective. Having a strong GitHub presence, a blog or a good portfolio of projects often goes further in showcasing what you can actually do.Study materialsThere are a ton of books and question banks out there for your CISSP prep–just make sure you’re using most recent ones. I’m a fan of digital materials, but I also enjoy writing notes by hand. I mainly used the Sybex Study Guide and the All-in-One Exam Guide, focusing on the parts I needed. Then I went through hundreds (if not thousands!) of practice questions to find my weak spots and went back to review those areas. Below are the resources that helped me the most:Oreilly libraryIf you can learn from digital materials instead of paper books, Oreilly library is definitely worth considering. It costs about $50 a month (as of October 2024) and gives you access to countless books and videos, including the Sybex Official Study Guide and some exam practice books. As this option is more cost-effective and environmentally friendly than buying physical books, it’s my default preference.Link: https://www.oreilly.com/search/?q=cissp&amp;rows=100Learnzapp Learnzapp is a great resource for practicing questions once you’ve read the books and tackled the questions they include. It offers both a mobile app and a web version, and you can even practice in a simulated exam mode to get a taste of the real attempt.I found it really helpful to see just how mentally draining it can be to answer over 100 questions in one sitting.Link: https://isc2-learnzapp.web.app/homeStudy Notes and Theory Another solid resource is the study materials and questions from Luke Ahmed. His question set is intentionally quite challenging, so I recommend using it after you’ve gone through all the other materials. Just avoid doing these questions right before the exam. Since they can be harder and trickier than the actual test, you might end up a bit discouraged or even completely lose confidence if you can’t hit that passing score!Link: https://www.studynotesandtheory.com/Destination Certification Videos Rob Witcher’s CISSP MindMaps are great for reviewing and pinpointing the areas you need to focus on more. The videos cover all the domains and summarize the key topics effectively.Link:https://www.youtube.com/watch?v=hf5NwUSEkwA&amp;list=PLZKdGEfEyJhLd-pJhAD7dNbJyUgpqI4puTechnical Institute of America I found Andrew Ramdayal’s videos just before the exam, and they really helped me feel confident about the topics. After tackling his 50 CISSP Practice Questions, I knew I was ready to take the exam.Link: https://www.youtube.com/watch?v=qbVY0Cg8NtwSummaryPassing the CISSP exam was a fantastic journey. I learned a ton, and I’m really glad I decided to give it a go. Even before the exam, I wasn’t sure if I was ready, but I tend to second-guess myself (and after all–who is ever fully ready?). I totally recommend CISSP for anyone who’s been in cybersecurity for a few years and wants a good overview of the field. The certification gained is just the cherry on top.Next on my list - looking at you, OSCP!" }, { "title": "OPA for User Registration", "url": "/posts/opa-registration/", "categories": "Authorization, IAM", "tags": "OPA, Intermediate", "date": "2024-06-30 04:00:00 +0000", "snippet": "BackgroundIdentity management is often far more complex in practice than it seems in theory. Simple user journeys quickly become convoluted when edge cases and exceptions are taken into account. Th...", "content": "BackgroundIdentity management is often far more complex in practice than it seems in theory. Simple user journeys quickly become convoluted when edge cases and exceptions are taken into account. This complexity is further amplified when identity management is being implemented for the first time in an organization, where a lack of standardization, identity silos, and poor data quality often present significant obstacles.In many cases, organizations have multiple identity stores tied to different applications, making it difficult to establish a unified view of the user. The process of generating a “golden record” — a single, unique, and well-defined user record compiled from various fragmented sources — becomes a daunting technical challenge. This complexity is further increased when business rules are not clearly defined upfront and need to be discovered and implemented during the process. Additionally, data quality is frequently compromised due to legacy systems and the natural erosion of information over time.Given these challenges, it is crucial to implement a robust and flexible identity management system capable of accommodating complex business rules. The system should use an approach that is both technically sound and easy to understand, minimizing issues during the translation of business logic into code. Furthermore, changes to these business rules should not necessitate a full software development lifecycle, but rather be managed as configuration changes, enabling faster and more adaptable updates.In this article, I explore a solution implementing a centralized policy decision point based on open-source components for just-in-time user registration. Please note that this is not intended as an evidence-based evaluation but rather a description of what worked for me in solving this problem, and it may help you as well. The approach outlined below uses Open Policy Agent (OPA) as a policy engine and has been successfully deployed in production for some time.GoalsFirst, let’s enumerate the goals for the system:FundamentalB1. The solution needs to be production ready and verified in a real-world scenario.B2. We don’t have unlimited budget, so the solution should be cost-effective, easy to maintain and modify.FunctionalF1. Encapsulate business logic in a separate component with easy interface.F2. Enable complex logic on user attributes and relations between them.F3. Fast JIT decision what actions identity management system should take (e.g., deny the process).F4. Generate data modification instructions for the identity management system.F5. Standardised way of defining rules, which can be extended with other use cases if needed.UsabilityU1. Business (aka non-technical employees) can understand the logic of the policy and even define their own rules.U2. Developers can understand the process and do not have to translate business requirements into code.U3. It is easy to introduce changes to the rules and integrate with the existing IDM stack.U4. Versioning following GitOps principles.DesignThe high-level design of the solution is as follows: IDM aggregates data from various sources. IDM creates a data bundle that represents the user. Bundle is sent to the evaluation engine. Evaluation engine uses the rules to make a decision. Evaluation engine returns the decision and actions to IDM.The diagram below shows the high-level design of the solution: flowchart LR A[Data Source A] &amp; B[Data Source B] &amp; C[Data Source C] -- User Data --&gt; IDM IDM -- Aggregated Data --&gt; EV[Evaluation engine] EV[Evaluation engine] -- Result --&gt; IDMProposed solutionEquipped with previous experience with OPA (Open Policy Agent) for access management,I want to use it for the user registration process.OPA allows you to evaluate policies which encode business logic using the rego language.OPA executes declarative policies completely decoupled from the application code. Any party in your system cansimply trigger a REST call to OPA engine with input data for evaluation.For example, below is a sample of a simple policy that checks access policy for API calls to the HTTP server (source OPA documentation):package httpapi.authzimport rego.v1# Bob is Alice's manager, and Betty is Charlie's.subordinates := {\"alice\": [], \"charlie\": [], \"bob\": [\"alice\"], \"betty\": [\"charlie\"]}default allow := false# Allow users to get their own salaries.allow if {\tinput.method == \"GET\"\tinput.path == [\"finance\", \"salary\", input.user]}# Allow managers to get their subordinates' salaries.allow if {\tsome username\tinput.method == \"GET\"\tinput.path = [\"finance\", \"salary\", username]\tsubordinates[input.user][_] == username}In this example based on the request metadata, the OPA engine makes decision to allow or deny access to the resource.For example, the data as shown below sent for the evaluation will result with result true.{ \"method\": \"GET\", \"path\": [\"finance\", \"salary\", \"alice\"], \"user\": \"alice\"}This can be easily extended to the user registration process to decide if a user should be registered or not. What about actions that should be taken by the IDM system? OPA can help with that as well.Instead of returning just true or false, the engine can return a complex JSON object that is constructed accordinglyto the rules shown in the implementation section.AlternativesBefore selecting OPA, I evaluated the approaches of building the rules engine from scratch as a native extension of the identity management system, as well as using a BPMN engine such as Camunda Zeebe.While native implementation is tempting with its flexibility, performance and tight integration with the IDM system, it fails to deliver on the usability side.Source code typically mixes business logic with language specific constructs, making it hard to understand for non-technical (and sometimes technical) employees.On top of that, designing and implementation of the rules engine is a significant development effort increasing the cost of the solution.My first thought of a viable solution that binds business logic and technical implementation was to use the BPMN engine.BRPN (Business Process Model and Notation) defines an XML-based representation of the business flow and binds it with software executions.Importantly, the flow design can be defined in the graphical editor without knowingthe underlying technology. While this approach might have worked, I found it too high-level for the task at hand.In my use case the logic needs to evaluate every single field of the user and make the decision.It would mean that steps of the BPMN had to be very granular which decreses performance (each one calls method in the BPMN worker) or the logic would have to be implemented in the worker which is very close to the native implementation.OPA to the rescueLet’s start with the evaluation of the requirements.OPA is definitely production-ready and tested by many companies (B1).The open-source version is sufficient for this use case, and the running cost is relatively small.The policy is defined as a text file and can be modified in any editor (B2). This completes our fundamental requirements.Regarding functional requirements, Rego files contain the entire business logic.The Rego file is evaluated in the OPA engine, a separate component (e.g., a Docker container) with a clear REST API.To get a policy decision, literally one REST API call is needed, so we have F1 covered.In the case of F2, the Rego language is powerful; however, I must admit that, with a typical software development mindset (i.e., writing step-by-step instructions to achieve results), defining the rules might not feel intuitive. For example, there are no for loops in Rego, and if statements are declared differently than what you might be familiar with in popular languages like Java or JavaScript (see more in rego design principles).However, thanks to this design, complex policies with broad and deep execution paths can be described concisely.Conditions between static data, input data, and dynamically calculated data can be easily defined.One drawback from my experience with Rego is that it is not a full-fledged programming language, and some operations available by default or through native libraries are missing. For example, simple geofencing calculations require basic mathematical operations like sine and cosine, which are not available in Rego. However, you can extend the Rego engine by writing Go code and including it in the OPA engine. Alternatively, in my case, I queried an external service for the result using OPA’s HTTP client.Therefore, I believe that the requirement F2 is sufficiently met.F3 is a strong point of OPA. The engine is very fast and can evaluate policies in a fraction of a second.For our complex policy (with over 2,000 lines of code), the evaluation time is between 2-4ms.Though this is not a benchmark result suitable for OPA performance comparisons, the outcome is far better than required for our use case, so F3 is met.OPA policies are not limited to returning a single boolean value. They can return a complex JSON object.With that, you can use policy rules to construct a JSON object that orchestrates actions to be taken by the IDM system.Actions like modifying a user’s email in Active Directory or updating contact information in the CRM system can be easily defined.In my case, OPA rules were used to construct LDAP LDIF files that were later executed by the IDM system.Therefore, F4 is met.Making complex rules simple is a challenge, and regardless of the technology, one can end up with spaghetti code.However, Rego has the advantage of flattening the logic and promoting the creation of short blocks that represent policy conditions.This contributes to the readability and standardization of rule definitions. Regarding extensibility, once created, a policy can be easily extended—up to the point that it breaks the agreed interface with the client (e.g., a new field in the response).But even then, the change is easy to introduce and does not require much effort.Therefore, F5 is met.Now let’s look at usability.To my surprise, OPA was easy to understand for the business. Once rules are named in understandable language (e.g., is_user_in_hr_group), the rule and entire policy become more like a recipe than code.I found that after initial training, non-technical employees were able to understand the policy and even define their own rules.Therefore, in my opinion, U1 is met.Easily understandable but technical representations of policy rules also benefit the development side.Business requirements, typically delivered as a set of plain English-described conditions, are much easier to translate into Rego code than into native code.The reverse is also true: once requirements are expressed in Rego, it is easier to perform reverse reasoning and understand the business logic.Therefore, U2 is met.Regarding U3, I have already discussed policy updates and integration via a single REST call.In terms of versioning (U4), rego files are text files that can be easily versioned using Git.Implementation examplesBelow, I share a few samples of how the policy can be implemented. PLease note that those exmaples are notcomplete and are simplified for the purpose of this article.Ex1. The policy is designed to have a single entry point. Below, you can see a rule called decision, which has a similarfunction as the main method in many programming languages. It is executed directly from the REST API, and defines the structure of the response. It aggregates results from other rules into a single JSON body.decision := response { response := { \"ruleImplemented\":rule_implemented, \"input\": policy_input, \"ldap\": ldap, \"error\": error, \"warn\": warn, \"metadata\": metadata, \"version\": policy_version, \"timestamp\": time.format(time.now_ns()) }}Ex2. The policy also runs the check of the data quality. If something is wrong thewarning message is added to the response. A similar approach is done for errors.warn[warn] { user_is_in_ldap count(ldap_attribute_x) == 0 warn := \"MISSING_LDAP_ATTRIBUTE_X: LDAP data is missing the x attribute\"}Ex3. As I mentioned before, the policy also creates steps for other systems to execute. The example below shows how an ldif modifyinstruction is created for an LDAP system.ldap := ldap_recs {\tldap_recs := {\t\t\"roles\":[{\t\t\t\"dn\": \"cn=member,ou=roles,dc=example,dc=com\",\t\t\t\"changetype\": \"modify\",\t\t\t\"add\": \"member\",\t\t\t\"member\": concat(\",\",[concat(\"=\",[\"uid\",input.username]),\"ou=users,ou=external,dc=example,dc=com\"])\t\t}]\t}}SummaryIn this article, I demonstrated how Open Policy Agent (OPA) can be used to implement centralized policy evaluation for just-in-time user registration. The solution is production-ready, cost-effective, and easy to maintain and modify. Additionally, it has the potential to be extended to other use cases, which I am currently exploring.The key takeaways are that, despite an initial learning curve, OPA and its Rego language offer powerful capabilities for implementing complex business logic. Another important point is that OPA can return more than just policy decisions, offering flexibility in its responses. Finally, I believe that the simplicity of Rego’s syntax, combined with well-structured naming conventions, can significantly reduce the gap between business requirements and technical implementation, minimizing friction and misunderstandings." } ]
